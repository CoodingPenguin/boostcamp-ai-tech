---
title: ⛺ DAY 10. 시각화 / 통계학
date: 2021-01-29 12:10:00
category: "⛺ Boostcamp"
thumbnail: "./img/10-thumbnail.png"
draft: false
---

![thumbnail](./img/10-thumbnail.png)

> 🙌은 **QnA에 있는 질문-답변**을 통해 얻은 지식을 표시합니다.

## [👉 피어 세션](https://github.com/boostcamp-ai-tech-4/peer-session/issues/41)

### 질문

- [[펭귄] 몬테카를로 방법을 활용하여 원주율에 대한 근사값 구하기](https://github.com/boostcamp-ai-tech-4/peer-session/issues/38)
- [[펭귄] 분류 문제에서 softmax 함수가 사용되는 이유가 뭘까요?](https://github.com/boostcamp-ai-tech-4/peer-session/issues/39)

### 기록

- 오늘은 이번 주에 나온 **Further Question**와 강의에 나온 수식들에 관해 이야기를 나누었다. 특히 왜 표본분산에서 $N-1$로 나누는지에 대해 길게 이야기를 했는데 자유도, 불편추정량 등의 의견이 오갔다. 대충 감은 잠았는데 아직도 많이 헷갈린다.
- [엠제이님이 남겨주신 답변](https://github.com/boostcamp-ai-tech-4/peer-session/issues/36)의 그래프에 대한 토의도 있었는데 파란선이 의미하는 바는 $x_0$를 입력으로 넣었을 때 정답 $t$일 확률을 말한다.
- 요새하는 **TMI 자기소개** 정말 좋다. 비대면으로 피어세션을 해서 서로를 소개할 기회가 없지 않을까 싶었는데 이렇게 서로를 이해할 수 있는 시간을 가질 수 있어서 참 좋다.

## Table of Contents

- [Matplotlib & Seaborn](#matplotlib--seaborn)
- [모수](#모수)
- [최대가능도 추정법](#최대가능도-추정법)
- [확률분포 거리](#확률분포-거리)
- [References](#references)

## Matplotlib & Seaborn

데이터 시각화를 할 때 자주 참고했던 자료들이다. 특히 [Seaborn Cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf)는 정말 자주 참고했다.

- [Python For Data Science Cheat Sheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf)
- [Simple Matplotlib & Visualization Tips](https://www.kaggle.com/subinium/simple-matplotlib-visualization-tips)
- [Basic of Statistical Viz : Plotly & Seaborn](https://www.kaggle.com/subinium/basic-of-statistical-viz-plotly-seaborn)

## 모수

통계적 모델링이란 **적절한 가정 위에서 확률분포를 추정**하는 것을 말한다. 하지만 유한한 개수의 데이터로 모집단의 분포를 정확히 알아내는 것은 불가능하므로 추정방법의 불확실성과 데이터를 고려하여 근사적으로 확률분포를 추정해야 한다.

모수란 **모집단의 특성**을 말한다. 예를 들면, 기댓값, 분산, 람다($\lambda$) 등이 있다. 우리는 데이터를 기반으로 모수를 추정하게 된다.

모수를 추정하는 방법은 다음과 같이 2가지로 나뉜다.

- `모수적 방법론`: 데이터가 특정 확률분포를 가진다 가정하고 모수를 추정하는 방법
- `비모수적 방법론`: 특정 확률분포를 가정하지 않고 모수를 추정하는 방법
  - 비모수의 뜻은 모수가 없다는 것이 아닌 **모수가 너무 많거나 데이터에 따라 모수가 변할 때** 비모수라고 한다.
  - 대부분의 머신러닝의 방법론은 비모수적 방법론에 속한다.

### 데이터의 확률분포 가정

1. **데이터를 생성하는 원리**를 고려한다.
2. 히스토그램이나 통계치를 보고 **모양을 관찰**한다.
   - 데이터 2개의 값(0 or 1)만 가지는 경우 → `베르누이분포`
   - 데이터가 $n$개의 이산적인 값을 가지는 경우 → `카테고리분포`
   - 데이터가 $[0, 1]$ 사이에서 값을 가지는 경우 → `베타분포`
   - 데이터가 0 이상의 값을 가지는 경우 → `감마분포`, `로그정규분포` 등
   - 데이터가 $\mathbb{R}$
3. 1, 2를 바탕으로 데이터의 확률분포를 **가정**한다.
4. 모수를 추정한 후 **검정**을 한다.

### 모수 추정

#### 표분분산과 표본평균

모집단에서 무작위로 샘플링한 **표본**을 확률변수 $X_1, X_2, X_3, ...$로 나타낸다고 하자. 이 표본들은 i.i.d.하다고 가정한다. 이 때 표본들의 평균과 분산을 다음과 같이 나타낼 수 있다.

$$
\bar{X} = \frac{1}{N} \sum^N_{i=1} X_i \qquad S^2 = \frac{1}{N-1} \sum^N_{i=1} (X_i - \bar{X})^2
$$

표본평균 $\bar{X}$의 기댓값은 $\mathbb{E}[\bar{X}]$, 표본분산 $S^2$의 기댓값은 $\mathbb{E}[S^2]$로 나타낼 수 있다. 표본평균의 평균과 표본분산의 평균을 통해 **모집단의 평균과 분산**을 추정할 수 있다.

<div class="quote-block">
<div class="quote-block__emoji">💡</div>
<div class="quote-block__content" markdown=1>

왜 표본분산을 구할 때 $N$이 아니라 $N-1$로 나눌까?

불편추정량(unbiased estimator)를 구하기 위해서이다. 여기서 불편추정량이란 편의가 없는 추정량을 말하며, 편의는 모수와 추정치의 차이를 말한다. $N$이 아닌 $N-1$로 나누었을 때가 모수를 더 정확히 추정하기 때문에 $N-1$로 나누는 것이다.

</div>
</div>

#### 중심극한정리

표본 $X_1, X_2, X_3, ... \sim i.i.d$이고, $E[X_i] = \mu, \quad Var[X_i] = \sigma^2$일 때, 임의의 실수 $a$에 대하여 다음을 만족한다. 이 때, $Z \sim N(0, 1)$의 분포를 띈다.

$$
P(\frac{\bar{X} - \mu}{\sigma / \sqrt{n}} ≤ a) \xrightarrow[\text{n → ∞}]\ P(Z ≤ a)
$$

이 식의 의미는 <u>표본의 크기인 $n$이 충분히 크면 표본평균의 분포는 모집단의 분포와 상관없이 표준정규분포에 가까워진다</u>는 것이다.

다음은 베르누이분포를 따르는 표본에 대해 표본 크기를 점차 증가할 때의 표본평균의 분포를 나타낸 것이다. 표본의 크기가 점점 커지면서 표본평균의 분포가 정규분포에 가까워지는 것을 볼 수 있다.

![중심극한정리](./img/10-central-limit-theorem.png)

<small class="src" markdown=1>

출처: [Daniel Resende - math](https://github.com/resendedaniel/math/tree/master/17-central-limit-theorem)

</small>

## 최대가능도 추정법

최대가능도 추정법(Maximum Likelihood Estimation, MLE)은 주어진 표본에 대해 **가능도를 가장 크게하는 모수 $\theta$**를 찾는 방법이다.

$$
\hat{\theta}_{MLE} = \underset{\theta}{argmax} \; L(θ;x) = \underset{\theta}{argmax} \; P(x|\theta)
$$

$$
L(\theta; X) = \prod_{i=1}^n P(x_i | \theta)
$$

가능도함수 $L(\theta; X)$는 모수 $\theta$를 따르는 분포가 $x$를 관찰한 가능성을 뜻하며, 확률밀도함수(pdf)나 확률질량함수(pmf)와는 전혀 다른 것이다.

**가능도 $L$과 확률 $P$는 무엇이 다를까?** 예를 들어 동전을 10번 던져서 앞면이 4번이 나왔다고 하자. `확률`은 위의 행동을 했을 때의 결과 즉, <u>앞면이 나올 확률</u>로 **$0.4$**이다. `가능도`는 <u>동전 앞면이 4번 나올 가능성</u>을 뜻하며, 앞면이 나올 확률을 $p$라고 할 때 이를 계산하면 **${}_{10}C_k \; p^k (1-p)^{10-k}$**이 된다. 이때 가능도가 최대가 되는 $p$는 0.5이다.

### 로그가능도

계산의 편의를 위해 가능도함수 $L$에 $\log$를 씌운 **로그가능도 함수**를 많이 사용한다. 이렇게 로그를 씌워도 최댓값의 위치는 변하지 않는다.

$$
\log L(\theta;X) = \sum^n_{i=1} \log P(x_i | \theta)
$$

### 최대가능도 추정법 예제

#### 예제1: 정규분포

정규분포를 따르는 확률변수 $X$로부터 독립적인 표본 ${x_1, ..., x_n}$을 얻었을 때 최대가능도 추정법으로 모수 $\mu, \sigma^2$을 구해보자. 모집단인 확률변수 $X$는 정규분포를 따르므로 **$X$의 확률밀도함수(pdf)**는 다음과 같다.

$$
f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

이 때 **로그가능도**를 구하면 다음과 같다.

$$
\log L(\mu, \sigma; X) = \sum^n_{i=1} \log P(x_i | \mu, \sigma^2) = \sum^n_{i=1} \log \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
$$

$$
= -\frac{n}{2} \log 2\pi\sigma^2 - \sum^n_{i=1} \frac{|x_i - \mu|^2}{2\sigma^2}
$$

가능도함수가 최대가 되는 $\mu, \sigma^2$를 구하려면, **$\mu$와 $\sigma$로 미분했을 때 모두 0이 되는 $\mu, \sigma^2$**를 구하면 된다.

$$
0 = \frac{\partial \log L}{\partial \mu} = -\sum_{i-1}^n \frac{x_i-\mu}{\sigma^2} \Rightarrow \hat{\mu}_{MLE}=\frac{1}{n}\sum^n_{i=1}x_i
$$

$$
0 = \frac{\partial \log L}{\partial \sigma} = -\frac{n}{\sigma}+\frac{1}{\sigma^3}\sum^n_{i=1}|x_i - \mu|^2 \Rightarrow \hat{\sigma}^2_{MLE}=\frac{1}{n}\sum^n_{i=1}(x_i-\mu)^2
$$

#### 예제2: 카테고리분포

카테고리분포($x; p_1, ..., p_d$)를 따르는 확률변수 $X$로부터 독립적인 표본 ${x_1, ..., x_n}$을 얻었을 때 최대가능도 추정법을 이용해 모수인 $p_k$를 추정해보자. 카테고리분포는 원-핫 벡터와 동일하며, **확률질량함수(pmf)**는 다음과 같다.

$$
f(x) = \prod_{i=1}^n \prod_{k=1}^d p^{x_{i, k}}_k
$$

위의 식을 설명하자면 $x_{i, k}$는 $i$번째 데이터의 벡터의 $k$번 째에 위치한 요소를 뜻하며 0 또는 1 값을 가진다. 예를 들어, $i$번째 데이터의 벡터가 `[0, 0, 0, 1, 0]`이라면 4번째에 위치한 요소 $x_{i, 4}$는 1이다. 이 때 $k$번째에 위치한 요소가 1일 확률을 $p_k$이다.

모집단이 다음과 같은 분포를 가질 때 **로그가능도 함수**를 구하면 다음과 같다. 이 때, $n_k = \sum^n_{i=1} x_{i, k}$이다.

$$
\log L(p_k; X) = \log \left(\prod_{i=1}^n \prod_{k=1}^d p^{x_{i, k}}_k \right)
$$

$$
= \sum^d_{k=1}\left(\sum^n_{i=1} x_{i, k}\right)\log p_k = \sum^d_{k=1} n_k \log p_k
$$

하지만 위의 식은 $\sum^d_{k=1} p_k = 1$이라는 제약조건이 있기 때문에 함부로 미분을 하면 안된다. 이 때 쓰는 방법이 **라그랑주 승수법**이며 이를 통해 제약조건이 있는 상황에서의 극점을 구할 수 있다. 라그랑주 승수법을 적용하여 새로운 목적식을 만들면 다음과 같다.

$$
\mathcal{L} (p_1, ..., p_k, \lambda) = \sum^d_{k=1} n_k \log p_k + \lambda (1- \sum_k p_k)
$$

이제 $p_k$와 $\lambda$로 미분해서 0이 되는 즉, **극점일 때의 $p_k$**를 찾아주면 된다.

$$
0 = \frac{\partial \mathcal{L}}{\partial p_k} = \frac{n_k}{p_k} - \lambda, \quad 0 = \frac{\partial \mathcal{L}}{\partial \lambda} = 1- \sum_{k=1}^{d} p_k
$$

$$
\Rightarrow p_k = \frac{n_k}{\sum_{k=1}^d n_k}
$$

### 딥러닝에서 최대가능도 추정법

최대가능도 추정법을 이용해서 **머신러닝 모델을 학습**할 수 있다. 딥러닝 모델의 가중치를 $\theta = (W^{(1)}, ..., W^{(L)})$ 나타냈을 때 분류 문제에서 소프트맥스(softmax) 벡터는 **카테고리분포의 모수 $(p_1, ... p_k)$를 추정**한다. 이 때 원-핫 벡터로 표현한 정답레이블 $y = (y_1, ..., y_k)$를 이용해 <u>확률분포인 소프트맥스 벡터의 로그가능도를 최적화</u>할 수 있다.

## 확률분포 거리

머신러닝에서 사용하는 손실함수(loss function)들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 **확률분포 거리**를 통해 유도된다. 확률분포 거리를 계산할 때 다음과 같은 함수를 사용한다.

- 총변동 거리(Total Variation Distance, TV)
- 쿨백-라이블러 발산(Kullback-Leibler Divergence, KL)
- 바슈타인 거리(Wasserstein Distance)

### 쿨백-라이블러 발산

쿨백-라이블러 발산은 확률변수가 `이산형`이냐 `연속형`이냐에 따라 다음과 같이 정의된다.

|                  |                                                                                           |
| :--------------: | :---------------------------------------------------------------------------------------: |
| **이산확률변수** | $\mathbb{KL}(P\|Q) = \sum_{x \in \mathcal{X}} P(x) \log \left( \frac{P(x)}{Q(x)} \right)$ |
| **연속확률변수** |  $\mathbb{KL}(P\|Q) = \inf_{\mathcal{X}} P(x) \log \left( \frac{P(x)}{Q(x)} \right) dx$   |

<br/>

쿨백-라이블러 발산은 크로스엔트로피와 엔트로피로 분해할 수 있다.

$$
\mathbb{KL}(P\|Q) = - \mathbb{E}_{x\sim P(x)}[\log Q(x)] + \mathbb{E}_{x\sim P(x)}[\log P(x)]
$$

- 🙌이 식에서 볼 수 있듯이 $\mathbb{KL}(P\|Q) ≠ \mathbb{KL}(Q\|P)$이다.
- 🙌 $\mathbb{KL}(P\|Q)$를 $Q$에 대해 상대적으로 $P$가 가지는 정보량의 차이로 생각할 수 있다. $\mathbb{KL}(Q\|P)$는 $P$가 기준이 되므로 이 둘은 절대 같을 수 없다.

<br/>

분류 문제에서 정답레이블 $P$, 모델로 예측한 레이블을 $Q$라 두면 최대가능도 추정법은 **쿨백-라이블러 발산을 최소화하는 것**과 같다. 즉, 로그가능도가 커질수록 확률분포 거리는 감소한다.

## References

- [확률및통계 홍영훈 교수님 정말 감사드립니다🙇‍♀️](https://sites.google.com/site/hong0108/)
- [불확실성 (Uncertainty) - 굿](https://seing.tistory.com/33)
- [불확실성의 의미를 아십니까?](https://www.slideshare.net/JungsikYu/ss-5338291)
- [9.2 최대가능도 추정법 - 데이터사이언스스쿨](https://datascienceschool.net/02%20mathematics/09.02%20%EC%B5%9C%EB%8C%80%EA%B0%80%EB%8A%A5%EB%8F%84%20%EC%B6%94%EC%A0%95%EB%B2%95.html)
- [1. 가능도와 가능도함수 - Must Learning with R](https://wikidocs.net/34034)
