---
title: â›º DAY 17. RNN, LSTM, GRU
date: 2021-02-16 19:02:00
category: "â›º Boostcamp"
thumbnail: "./img/17-thumbnail.png"
draft: false
---

![thumbnail](./img/17-thumbnail.png)

> ğŸ™Œì€ **QnAì— ìˆëŠ” ì§ˆë¬¸-ë‹µë³€**ì„ í†µí•´ ì–»ì€ ì§€ì‹ì„ í‘œì‹œí•©ë‹ˆë‹¤.

## [ğŸ‘‰ í”¼ì–´ ì„¸ì…˜](https://github.com/boostcamp-ai-tech-4/peer-session/issues/64)

### ì§ˆë¬¸

- [[íˆìŠ¤] LSTMê³¼ GRU ëŠ” ë°±í”„ë¡œíŒŒê²Œì´ì…˜ì„ ì…€ ìŠ¤í…Œì´íŠ¸ì— ëŒ€í•´ì„œë§Œ í•˜ë‚˜ìš”?](https://github.com/boostcamp-ai-tech-4/peer-session/issues/66)
- [[íˆìŠ¤] Word2Vector ì˜ ëª©ì ](https://github.com/boostcamp-ai-tech-4/peer-session/issues/65)
- [[í­ê·„] ì–‘ë°©í–¥ RNN/LSTMì€ ì–´ë–¤ ì‹ìœ¼ë¡œ í•™ìŠµì„ í•˜ë‚˜ìš”?](https://github.com/boostcamp-ai-tech-4/peer-session/issues/67)
- [[í­ê·„] (FQ) RNN/LSTM/GRUê³¼ BPTT](https://github.com/boostcamp-ai-tech-4/peer-session/issues/68)
- [[í­ê·„] (FQ) Word2Vecê³¼ GloVeì˜ ë‹¨ì ](https://github.com/boostcamp-ai-tech-4/peer-session/issues/69)

### ê¸°ë¡

- ì˜¤ëŠ˜ì€ **ì €ë²ˆ RNN, LSTM/GRUì˜ ë³µìŠµ ì‹œê°„ê°™ì€ ê°•ì˜**ì˜€ë‹¤. ê³µë¶€ëŠ” í•˜ê¸´í–ˆì–´ë„ ì‚´ì§ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ì´ ìˆì—ˆëŠ”ë° ê·¸ëŸ° ë¶€ë¶„ì„ ë§ˆìŠ¤í„°ë‹˜ê»˜ì„œ ì˜ˆì‹œë¥¼ ë“¤ì–´ì„œ ì˜ ì„¤ëª…í•´ì£¼ì…”ì„œ ì´í•´í•  ìˆ˜ ìˆì—ˆë‹¤. íŠ¹íˆ Vanishing Gradient ë¬¸ì œëŠ” ì™„ì „íˆ ì´í•´í–ˆë‹¤!
- í”¼ì–´ì„¸ì…˜ì—ì„œëŠ” ë‚´ì¼ ìˆì„ ë§ˆìŠ¤í„°ë‹˜ê»˜ ë“œë¦´ ì§ˆë¬¸ì„ ì •í•˜ê³  ê°•ì˜ì—ì„œ ê¶ê¸ˆí–ˆë˜ ì ì„ ë¬¼ì–´ë³´ëŠ” ì‹œê°„ì„ ê°€ì¡Œë‹¤. ê·¸ ì¤‘ [Teacher Forcing](https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/)ì— ê´€ë ¨ëœ ì§ˆë¬¸ì´ ë‚˜ì™”ëŠ”ë° íŒ€ì›ë“¤ë¼ë¦¬ ì´ì•¼ê¸°í•˜ëŠ” ê²ƒì„ ë“£ë‹¤ë³´ë‹ˆ ë‚˜ë„ ì´í•´ëª»í•œ ë¶€ë¶„ì´ ì´í•´ê°€ ë˜ì„œ ê·¸ê²ƒì„ ë§í–ˆë”ë‹ˆ "ì„¤ëª…ì„ ê¹”ë”í•˜ê²Œ í–ˆë‹¤"ê³  ì¹­ì°¬ì„ ë°›ì•˜ë‹¤ğŸ˜Š

## Table of Contents

> âœ [DAY 14. Recurrent Neural Network](../day14-20210204)ì— ìˆëŠ” ë‚´ìš© ì™¸ì˜ ê²ƒë§Œ ì •ë¦¬í•©ë‹ˆë‹¤!

- [RNN](#rnn)
- [LSTMê³¼ GRU](#lstmê³¼-gru)
- [References](#references)

## RNN

[ğŸ‘€ DAY 14ì˜ RNN ë‚´ìš© ë³´ëŸ¬ê°€ê¸°](../day14-20210204/#rnn-recurrent-neural-network)

### Hidden State

![](./img/17-rnn.png)
<small class="src" markdown=1>

ì¶œì²˜: [CS231n Lecture 10. Recurrent Neural Network](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture10.pdf)

</small>

- hidden stateì¸ $h_t$ëŠ” í˜„ì¬ì˜ ì…ë ¥ $x_t$ì™€ ì´ì „ timeì˜ hidden state $h_{t-1}$ì˜ ì„ í˜• ê²°í•©ì„ í†µí•´ ë§Œë“¤ ìˆ˜ ìˆë‹¤.
  - ì´ ë•Œ, $x_t \rightarrow h_t$ë¡œ ë°”ê¿”ì£¼ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ $W_{xh}$, $\; h_{t-1} \rightarrow h_t$ë¡œ ë°”ê¿”ì£¼ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ $W_{hh}$ë¼ê³  í•œë‹¤.
  - ê° í–‰ë ¬ê³¼ì˜ ì—°ì‚° ê²°ê³¼ë¥¼ concatí•˜ë©´ $h_t$ê°€ ëœë‹¤.
- ë§Œì•½ $y$ë¥¼ ì¶œë ¥í•´ì•¼ í•œë‹¤ë©´, ë¹„í™œì„±í™” í•¨ìˆ˜ `tanh`ë¥¼ í†µê³¼ì‹œí‚¤ê³  ì¶œë ¥ê°’ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬ $W_{hy}$ë¥¼ í†µê³¼ì‹œì¼œ ê³„ì‚°í•œë‹¤.

<div class="quote-block">
<div class="quote-block__emoji">ğŸ’¡</div>
<div class="quote-block__content" markdown=1>

hidden stateì˜ ì—­í• ì´ ë¬´ì—‡ì¸ê°€ìš”?

hidden stateëŠ” **ì´ì „ time stepì˜ ì •ë³´ë¥¼ ê¸°ì–µí•˜ëŠ” ì—­í• **ì„ í•œë‹¤. ì˜ˆë¥¼ ë“¤ë©´, Cì–¸ì–´ ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” RNN ëª¨ë¸ì´ ìˆë‹¤ê³  í•˜ì. ì—¬ê¸°ì„œ hidden stateì˜ í•œ ë…¸ë“œëŠ” ì¤‘ê´„í˜¸ `{}`ê°€ ì—´ë ¸ëŠ”ì§€ í˜¹ì€ ë‹«í˜”ëŠ”ì§€ë¥¼ ê¸°ì–µí•œë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)ì—ì„œ hidden stateë¥¼ visualizingí•œ ë¶€ë¶„ì„ ì°¸ê³ !

</div>
</div>

### RNNì˜ ì¢…ë¥˜

![](./img/17-rnn-types.png)
<small class="src" markdown=1>

ì¶œì²˜: [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

</small>

- **one-to-one**: ì…ì¶œë ¥ì— time stepì´ ì—†ëŠ” ì¼ë°˜ì ì¸ ëª¨ë¸ì´ë‹¤.
- **one-to-many**: 1ê°œì˜ ì…ë ¥ì„ ë°›ì•„ ì—¬ëŸ¬ time stepì˜ ì¶œë ¥ì„ ë‚´ë³´ë‚´ëŠ” ëª¨ë¸ì´ë‹¤. ë‘ ë²ˆì§¸ time stepë¶€í„°ëŠ” ì…ë ¥ í¬ê¸°ì™€ ë™ì¼í•œ ì˜ë²¡í„°ê°€ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°„ë‹¤.
  - `ex` ì´ë¯¸ì§€ ìº¡ì…”ë‹
- **many-to-one**: time stepì´ ìˆëŠ” ì…ë ¥ì„ ë„£ì–´ 1ê°œì˜ ì¶œë ¥ì„ ë‚´ë³´ë‚´ëŠ” ëª¨ë¸ì´ë‹¤. ë§ˆì§€ë§‰ hidden stateì— ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ í†µê³¼ì‹œì¼œ ìµœì¢… ì¶œë ¥ê°’ì„ ê³„ì‚°í•œë‹¤.
  - `ex` ê°ì • ë¶„ì„
- **many-to-many**: ì…ì¶œë ¥ì´ ëª¨ë‘ ì‹œí€€ìŠ¤ì¸ ëª¨ë¸ë¡œ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ëª¨ë‘ ë„£ì€ ë‹¤ìŒ ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥ ì‹œí€€ìŠ¤ë¥¼ ë‚´ë³´ë‚¸ë‹¤.
  - `ex` ê¸°ê³„ë²ˆì—­
- **many-to-many**: ì…ë ¥ì´ ì£¼ì–´ì§ˆ ë•Œë§ˆë‹¤ ì¶œë ¥ì„ í•˜ëŠ” delayê°€ ì—†ëŠ” ëª¨ë¸ì´ë‹¤.
  - `ex` PoS íƒœê¹…, ì˜ìƒ í”„ë ˆì„ ë¶„ë¥˜

### Vanishing/Exploding Gradient ë¬¸ì œ

RNNì€ ìˆœí™˜êµ¬ì¡°ë¡œ <u>ì „ time stepì˜ hidden stateë¥¼ ë‹¤ì‹œ ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ ìƒˆë¡œìš´ hidden stateë¥¼ ë§Œë“œëŠ” êµ¬ì¡°</u>ì´ë‹¤. ì´ë¥¼ ëª…ì‹¬í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ 3ë²ˆì˜ ì…ë ¥ì„ ë°›ëŠ” ë‹¨ìˆœí•œ RNN ëª¨ë¸ì´ ìˆë‹¤ê³  í•´ë³´ì.

---

![](./img/17-gradient-vanishing.png)

---

BPTTë¡œ ê¸°ìš¸ê¸° $\frac{\partial{L}}{\partial h_1}$ì„ êµ¬í•œë‹¤ê³  í•  ë•Œ, $\frac{\partial{L}}{\partial h_1} = \frac{\partial{L}}{\partial h_3} \cdot \frac{\partial{h_3}}{\partial h_1}$ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. ì´ ë•Œ $\frac{\partial{h_3}}{\partial h_1}$ì„ êµ¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\frac{\partial{h_3}}{\partial h_1} = tanh'(X) \cdot 3tanh'(Y) \cdot 3
$$

<small markdown=1>

$$
(X = 2x_3+3tanh(Y)+1, \quad Y = 2x_2+3h_1+1)
$$

</small>

ìœ„ì˜ ì‹ì„ ë³´ë©´ ê¸°ìš¸ê¸° $W_{hh}$ì¸ 3ì´ ë‘ ë²ˆ ê³±í•´ì§„ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë§Œì•½ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ 3ê°œê°€ ì•„ë‹Œ 100ê°œ, 1000ê°œ ì˜€ë‹¤ë©´ $W_{hh}$ê°€ 100ë²ˆ, 1000ë²ˆ ëˆ„ì ì´ ë  ê²ƒì´ë‹¤.

ì´ ë•Œë¬¸ì— $W_{hh}$ì˜ ê°’ì´ 1ë³´ë‹¤ í¬ë©´ `Exploding Gradient`ë¬¸ì œê°€, 1ë³´ë‹¤ ì‘ìœ¼ë©´ `Vanishing Gradient`ë¬¸ì œê°€ ë°œìƒí•œë‹¤.

## LSTMê³¼ GRU

[ğŸ‘€ DAY 14ì˜ LSTM/GRU ë‚´ìš© ë³´ëŸ¬ê°€ê¸°](../day14-20210204/#lstm-long-short-term-memory)

### í–‰ë ¬ë¡œ ë³´ëŠ” LSTM

ì•ì„œ ë´¤ë˜ Input Gate, Forget Gate, Output Gateë¥¼ ë‹¤ìŒê³¼ ê°™ì´ $W$ì™€ì˜ ì„ í˜•ê²°í•©ê³¼ ë¹„í™œì„±í•¨ìˆ˜ë¡œ êµ¬í•  ìˆ˜ ìˆë‹¤.

![](./img/17-lstm.png)

- $i$: Input Gateë¡œ, $g$ì—ì„œ í•„ìš”ìˆëŠ” ì •ë³´ë¥¼ í•„í„°ë§í•˜ëŠ” ì—­í• ì„ í•œë‹¤.
- $f$: Forget Gateë¡œ, $c_{t-1}$ì—ì„œ í•„ìš”ì—†ëŠ” ì •ë³´ë¥¼ ê±¸ëŸ¬ë‚´ëŠ” ì—­í• ì„ í•œë‹¤.
- $o$: Output Gateë¡œ, $c_t$ì—ì„œ ì–¼ë§ˆë§Œí¼ì„ ì¶œë ¥ìœ¼ë¡œ ë‚´ë³´ë‚¼ ê±´ì§€ ê²°ì •í•œë‹¤.
- $g$: Gate Gateë¡œ, ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ $x_t$ì™€ $h_{t-1}$ë¡œ ë§Œë“  cell state í›„ë³´êµ°ì„ ë§í•œë‹¤.

### ì–´ë–»ê²Œ Vanishing/Exploding Gradient ë¬¸ì œë¥¼ í•´ê²°í• ê¹Œ?

LSTMì„ ìƒê°í•´ë³´ì. LSTMì˜ cell stateì— ëŒ€í•œ ê³„ì‚°ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
C_t = f_t * C_{t-1} + i_t *  \widetilde{C}_t
$$

ì´ ë•Œ, $C_T$ë¥¼ $C_t$ì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. $(T > t)$

$$
\frac{\partial C_T}{\partial C_t} = \frac{\partial C_T}{\partial C_{T-1}}  \frac{\partial C_{T-1}}{\partial C_{T-2}}  \cdots  \frac{\partial C_{t+1}}{\partial C_t}
$$

$\frac{\partial C_T}{\partial C_{T-1}} = f_T, ... , \frac{\partial C_{t+1}}{\partial C_t} = f_{t+1}$ì´ë¯€ë¡œ, ìœ„ì˜ ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤.

$$
\frac{\partial C_T}{\partial C_t} = \prod_{i=t+1}^T f_i
$$

ì•ì„œ ë³´ì•˜ë˜ $W_{hh}$ì™€ tanhì˜ ê³±ìœ¼ë¡œ í‘œí˜„ëœ RNNì˜ ë¯¸ë¶„ì‹ê³¼ ë‹¬ë¦¬ ì˜¤ì§ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ê²°ê³¼ê°’ì¸ $f_i$ì˜ ê³±ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì§€ë¯€ë¡œ RNNë³´ë‹¤ëŠ” Vanishing/Exploding Gradient ë¬¸ì œê°€ ì–´ëŠ ì •ë„ í•´ê²°ëœë‹¤. GRUë„ LSTMê³¼ ë¹„ìŠ·í•œ ì´ìœ ë¡œ í•´ë‹¹ ë¬¸ì œê°€ í•´ê²°ëœë‹¤.

<div class="quote-block">
<div class="quote-block__emoji">ğŸ’¡</div>
<div class="quote-block__content" markdown=1>

LSTM/GRUëŠ” ê¶ê·¹ì ìœ¼ë¡œ Vanishing/Exploding Gradient ë¬¸ì œë¥¼ í•´ê²°í–ˆì„ê¹Œ?

ë‹¹ì—°íˆ ì•„ë‹ˆë‹¤! ìœ„ì˜ ì‹ìœ¼ë¡œë§Œ ë´ë„ ì‹œê·¸ëª¨ì´ë“œì— ì˜í•´ ê¸°ìš¸ê¸°ëŠ” ì¡°ê¸ˆì”© ì†Œì‹¤ë  ê²ƒì´ë‹¤. ë‹¤ë§Œ, RNNê³¼ ë‹¬ë¦¬ ê°€ì¤‘ì¹˜ $W$ê°€ ê³±í•´ì§€ì§€ ì•Šê¸° ë•Œë¬¸ì— ë¬¸ì œê°€ ëŠ¦ê²Œ ì˜¬ ë¿ì´ë‹¤.

[ì—¬ê¸°](https://imgur.com/gallery/vaNahKE)ë¥¼ ë³´ë©´ LSTMë„ ì˜¤ë˜ëœ ê³¼ê±° stepê¹Œì§€ ê±°ìŠ¬ë¡œ ì˜¬ë¼ê°”ì„ ë•Œ ê¸°ìš¸ê¸°ê°€ ì†Œì‹¤ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

</div>
</div>

## References

- [LSTMê°€ gradient vanishingì— ê°•í•œì´ìœ ? - Hello Blog!](https://curt-park.github.io/2017-04-03/why-is-lstm-strong-on-gradient-vanishing/)
- [How does LSTM prevent the vanishing gradient problem? - StackExchange](https://stats.stackexchange.com/questions/185639/how-does-lstm-prevent-the-vanishing-gradient-problem)
